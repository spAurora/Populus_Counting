{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n胡杨拆解计数\\n~~~~~~~~~~~~~~~~\\ncode by wHy\\nAerospace Information Research Institute, Chinese Academy of Sciences\\nGhent University\\nHaoyu.Wang@ugent.be\\n'"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\"\"\"\n",
    "Individual Populus Trees detection\n",
    "~~~~~~~~~~~~~~~~\n",
    "code by wHy\n",
    "Aerospace Information Research Institute, Chinese Academy of Sciences\n",
    "Ghent University\n",
    "Haoyu.Wang@ugent.be\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import gdal\n",
    "import ogr\n",
    "import os\n",
    "import osr\n",
    "\n",
    "from PIL import Image\n",
    "from pylab import *\n",
    "from scipy.ndimage import filters\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "\n",
    "import math\n",
    "from skimage import io, color\n",
    "import numpy as np\n",
    "from skimage import img_as_ubyte\n",
    "from skimage import img_as_float\n",
    "from tqdm import tqdm\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import fnmatch\n",
    "from collections import deque\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_img(out_path, im_proj, im_geotrans, im_data):\n",
    "    \"\"\"output img\n",
    "    Args:\n",
    "        out_path: Output path\n",
    "        im_proj: Affine transformation parameters\n",
    "        im_geotrans: spatial reference\n",
    "        im_data: Output image data\n",
    "    \"\"\"\n",
    "    # identify data type \n",
    "    if 'int8' in im_data.dtype.name:\n",
    "        datatype = gdal.GDT_Byte\n",
    "    elif 'int16' in im_data.dtype.name:\n",
    "        datatype = gdal.GDT_UInt16\n",
    "    else:\n",
    "        datatype = gdal.GDT_Float32\n",
    "\n",
    "    # calculate number of bands\n",
    "    if len(im_data.shape) > 2:  \n",
    "        im_bands, im_height, im_width = im_data.shape\n",
    "    else:  \n",
    "        im_bands, (im_height, im_width) = 1, im_data.shape\n",
    "\n",
    "    # create new img\n",
    "    driver = gdal.GetDriverByName(\"GTiff\")\n",
    "    new_dataset = driver.Create(\n",
    "        out_path, im_width, im_height, im_bands, datatype)\n",
    "    new_dataset.SetGeoTransform(im_geotrans)\n",
    "    new_dataset.SetProjection(im_proj)\n",
    "    if im_bands == 1:\n",
    "        new_dataset.GetRasterBand(1).WriteArray(im_data.squeeze())\n",
    "    else:\n",
    "        for i in range(im_bands):\n",
    "            new_dataset.GetRasterBand(i + 1).WriteArray(im_data[i])\n",
    "\n",
    "    del new_dataset\n",
    "\n",
    "def read_img(sr_img):\n",
    "    \"\"\"read img\n",
    "    Args:\n",
    "        sr_img: The full path of the original image\n",
    "    \"\"\"\n",
    "    im_dataset = gdal.Open(sr_img)\n",
    "    if im_dataset == None:\n",
    "        print('open sr_img false')\n",
    "        sys.exit(1)\n",
    "    im_geotrans = im_dataset.GetGeoTransform()\n",
    "    im_proj = im_dataset.GetProjection()\n",
    "    im_width = im_dataset.RasterXSize\n",
    "    im_height = im_dataset.RasterYSize\n",
    "    im_bands = im_dataset.RasterCount \n",
    "    im_data = im_dataset.ReadAsArray(0, 0, im_width, im_height)\n",
    "    del im_dataset\n",
    "\n",
    "    return im_data, im_proj, im_geotrans, im_height, im_width, im_bands\n",
    "\n",
    "def imagexy2geo(trans, row, col):\n",
    "    '''\n",
    "    根据GDAL的六参数模型将影像图上坐标（行列号）转为投影坐标或地理坐标（根据具体数据的坐标系统转换）\n",
    "    :param dataset: GDAL地理数据\n",
    "    :param row: 像素的行号\n",
    "    :param col: 像素的列号\n",
    "    :return: 行列号(row, col)对应的投影坐标或地理坐标(x, y)\n",
    "    '''\n",
    "    px = trans[0] + col * trans[1] + row * trans[2]\n",
    "    py = trans[3] + col * trans[4] + row * trans[5]\n",
    "    return px, py\n",
    "\n",
    "def write_point_to_layer(coord, out_lyr, def_out_feature):\n",
    "    \"\"\"\n",
    "    write point features in layer\n",
    "    \"\"\"\n",
    "    point = ogr.Geometry(ogr.wkbPoint)\n",
    "    point.AddPoint(coord[0], coord[1])\n",
    "    outfeat = ogr.Feature(def_out_feature)  # 定义输出要素\n",
    "    outfeat.SetGeometry(point)  # 设置要素几何\n",
    "    outfeat.SetField2('type', coord[2]) # 写入类别\n",
    "    out_lyr.CreateFeature(outfeat)  # 图层新建要素\n",
    "    outfeat = None\n",
    "\n",
    "def formatted_write_opencv_img(img_data, write_path, img_name, prefix, suffix, im_proj, im_geotrans):\n",
    "    \"\"\"\n",
    "    opencv格式化输出\n",
    "    \"\"\"\n",
    "    time.sleep(1)\n",
    "    if len(img_data.shape) > 2:\n",
    "        output_img_data = cv2.cvtColor(img_data, cv2.COLOR_BGR2RGB)\n",
    "        output_img_data = output_img_data.transpose(2, 0, 1)\n",
    "        output_full_path = write_path + '/' + prefix + img_name[:-4] + suffix + '.tif'\n",
    "        write_img(output_full_path, im_proj, im_geotrans, output_img_data)\n",
    "    else:\n",
    "        output_full_path = write_path + '/' + prefix + img_name[:-4] + suffix + '.tif'\n",
    "        write_img(output_full_path, im_proj, im_geotrans, img_data)\n",
    "\n",
    "def euclidean_distance(matrix1, matrix2):\n",
    "    \"\"\"计算两个矩阵的欧式距离\n",
    "    \"\"\"\n",
    "    # 将两个矩阵展平为向量\n",
    "    vector1 = matrix1.flatten().astype(np.float64)\n",
    "    vector2 = matrix2.flatten().astype(np.float64)\n",
    "    \n",
    "    # 计算欧氏距离\n",
    "    distance = np.sqrt(np.sum((vector1 - vector2) ** 2))\n",
    "    \n",
    "    return distance\n",
    "\n",
    "def average_euclidean_distance(matrix1, matrix2, circle_mask):\n",
    "    \"\"\"计算两个矩阵的平均欧式距离\n",
    "    \"\"\"\n",
    "    # 将两个矩阵展平为向量\n",
    "    bands = shape(matrix1)[2]\n",
    "    circle_mask_expand_bands = np.zeros((shape(matrix1)[0],shape(matrix1)[1],shape(matrix1)[2]))\n",
    "    for i in range(bands):\n",
    "        circle_mask_expand_bands[:,:,i] = circle_mask\n",
    "\n",
    "    vector1 = matrix1.flatten().astype(np.float64)\n",
    "    vector2 = matrix2.flatten().astype(np.float64)\n",
    "    vector3 = circle_mask_expand_bands.flatten()\n",
    "    \n",
    "    # 计算每个像素之间的欧氏距离\n",
    "    pixel_distances = vector3 * np.sqrt((vector1 - vector2) ** 2)\n",
    "    \n",
    "    # 计算平均欧氏距离\n",
    "    average_distance = np.sum(pixel_distances)/sum(vector3)\n",
    "    \n",
    "    return average_distance\n",
    "\n",
    "def cal_patch_march_num(tmp_labels, circle_mask):\n",
    "    \"\"\"返回匹配的像素总数\n",
    "    \"\"\"\n",
    "    return np.sum(tmp_labels * circle_mask)\n",
    "\n",
    "def cal_lockmap_match_num(lock_map_patch, circle_mask):\n",
    "    \"\"\"返回匹配锁定图像素总数\n",
    "    \"\"\"\n",
    "    return np.sum(lock_map_patch * circle_mask)\n",
    "\n",
    "\n",
    "def geo2imagexy(geoX, geoY, im_geotrans):\n",
    "    # 地理坐标系转图上坐标系\n",
    "    g0 = float(im_geotrans[0])\n",
    "    g1 = float(im_geotrans[1])\n",
    "    g2 = float(im_geotrans[2])\n",
    "    g3 = float(im_geotrans[3])\n",
    "    g4 = float(im_geotrans[4])\n",
    "    g5 = float(im_geotrans[5])\n",
    "\n",
    "    x = (geoX*g5 - g0*g5 - geoX*g2 + g3*g2)/(g1*g5 - g4*g2)\n",
    "    y = (geoY - g3 - geoX*g4)/ g5\n",
    "\n",
    "    return x, y\n",
    "\n",
    "def write_to_log(log_filename, log_message):\n",
    "    # 打开日志文件，如果不存在则创建\n",
    "    with open(log_filename, 'a') as log_file:\n",
    "        # 获取当前时间\n",
    "        \n",
    "        # 构造要写入日志文件的内容\n",
    "        log_entry = f'{log_message}'\n",
    "        \n",
    "        # 将日志内容写入文件\n",
    "        log_file.write(log_entry)\n",
    "\n",
    "def truncated_linear_stretch(image, truncated_value, max_out = 255, min_out = 0):\n",
    "    # 图像拉伸\n",
    "    def gray_process(gray):\n",
    "        nonzero_pixels = gray[gray != 0] # 0不参与计算\n",
    "\n",
    "        if len(nonzero_pixels) == 0:\n",
    "        # 如果所有像素都是0，返回原始图像\n",
    "            return gray\n",
    "\n",
    "        truncated_down = np.percentile(nonzero_pixels, truncated_value)\n",
    "        truncated_up = np.percentile(nonzero_pixels, 100 - truncated_value)\n",
    "        gray = (gray - truncated_down) / (truncated_up - truncated_down) * (max_out - min_out) + min_out \n",
    "        gray[gray < min_out] = min_out\n",
    "        gray[gray > max_out] = max_out\n",
    "        if(max_out <= 255):\n",
    "            gray = np.uint8(gray)\n",
    "        elif(max_out <= 65535):\n",
    "            gray = np.uint16(gray)\n",
    "        return gray\n",
    "    \n",
    "    #  如果是多波段\n",
    "    if(len(image.shape) == 3):\n",
    "        image_stretch = []\n",
    "        for i in range(image.shape[0]):\n",
    "            gray = gray_process(image[i])\n",
    "            image_stretch.append(gray)\n",
    "        image_stretch = np.array(image_stretch)\n",
    "    #  如果是单波段\n",
    "    else:\n",
    "        image_stretch = gray_process(image)\n",
    "    return image_stretch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 每做一组实验需要：\n",
    "# 1. 检查sr_img_path，semantic_segmentation_result_path是否正确\n",
    "# 2. 修改output_img_path和output_shp_path最后的路径(最后1个或者2个)\n",
    "# 3. 修改实验相关参数\n",
    "\n",
    "sr_img_path = r'C:\\Users\\75198\\OneDrive\\论文\\SCI-4 Populus counting\\1-evaluation\\1-clip_img_d2'\n",
    "semantic_segmentation_result_path = r'C:\\Users\\75198\\OneDrive\\论文\\SCI-4 Populus counting\\1-evaluation\\2-ss_d2'\n",
    "output_img_path = r'C:\\Users\\75198\\OneDrive\\论文\\SCI-4 Populus counting\\1-evaluation\\4-predict\\TS_7-21_d2'\n",
    "output_shp_path = r'C:\\Users\\75198\\OneDrive\\论文\\SCI-4 Populus counting\\1-evaluation\\4-predict\\TS_7-21_d2'\n",
    "glt = 0.9\n",
    "mlt = 0.8\n",
    "\n",
    "foreground_value = 1\n",
    "template_path = r'C:\\Users\\75198\\OneDrive\\论文\\SCI-4 Populus counting\\画图\\图6-模版结果图'\n",
    "log_file_name = r'C:\\Users\\75198\\OneDrive\\论文\\SCI-4 Populus counting\\画图\\实验日志.txt'\n",
    "\n",
    "if not os.path.exists(output_img_path):\n",
    "    os.mkdir(output_img_path)\n",
    "if not os.path.exists(output_shp_path):\n",
    "    os.mkdir(output_shp_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21, 21, 3) uint8\n",
      "[21, 19, 17, 15, 13, 11, 9, 7]\n"
     ]
    }
   ],
   "source": [
    "'''读取模板'''\n",
    "'''模板由plt_template.ipynb计算生成'''\n",
    "\n",
    "# 注意，必须由大到小排列\n",
    "Tempalte = []\n",
    "#Tempalte.append(np.load(template_path + '/1_19_21.npy'))\n",
    "#Tempalte.append(np.load(template_path + '/1_17_19.npy'))\n",
    "Tempalte.append(np.load(template_path + '/1_15_17.npy')) # opencv BGR (h,w,c) uint8 \n",
    "Tempalte.append(np.load(template_path + '/1_13_15.npy'))\n",
    "Tempalte.append(np.load(template_path + '/1_11_13.npy'))\n",
    "Tempalte.append(np.load(template_path + '/1_9_11.npy'))\n",
    "Tempalte.append(np.load(template_path + '/1_7_9.npy'))\n",
    "Tempalte.append(np.load(template_path + '/1_5_7.npy'))\n",
    "# Tempalte.append(np.load(template_path + '/1_0_5.npy'))\n",
    "\n",
    "T_num = len(Tempalte) # 模板数量\n",
    "\n",
    "print(shape(Tempalte[0]), Tempalte[0].dtype)\n",
    "c_size = []\n",
    "for i in range(T_num):\n",
    "    c_size.append(shape(Tempalte[i])[0])\n",
    "print(c_size)\n",
    "\n",
    "'''生成对应的圆蒙版'''\n",
    "circle_masks = []\n",
    "circle_valid_sums = []\n",
    "\n",
    "# 蒙版\n",
    "for k in range(T_num):\n",
    "    circle_mask = np.zeros((c_size[k], c_size[k]), dtype=np.int32)\n",
    "    circle_radius = c_size[k]//2\n",
    "    circle_center = (c_size[k]//2, c_size[k]//2)  # 圆心的坐标，这里假设圆心位于矩阵中心\n",
    "    # 遍历矩阵中的每个像素，并计算与圆心的距离\n",
    "    for i in range(c_size[k]): # 注意修改c_size\n",
    "        for j in range(c_size[k]):\n",
    "            distance = np.sqrt((i - circle_center[0])**2 + (j - circle_center[1])**2)\n",
    "            if distance <= circle_radius:\n",
    "                circle_mask[i, j] = 1\n",
    "    circle_masks.append(circle_mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[282.6, 228.6, 180.9, 137.70000000000002, 101.7, 70.2, 45.0, 39.2]\n"
     ]
    }
   ],
   "source": [
    "shandow_threshold = 160 # 识别为阴影的阈值\n",
    "minimum_threshold = 3 # 单株胡杨的最低识别阈值 长宽均大于该阈值才被视为单株胡杨\n",
    "skip_threshold = 0.3 # 任意一个patch的有效像素的比例必须大于该值，才被视为有效像素 230920对于小模板是否应该调低这个阈值待测试\n",
    "\n",
    "suit_map_binary_values = []\n",
    "for i in range(T_num): \n",
    "    suit_map_binary_values.append(10)\n",
    "\n",
    "max_distances = [] # 树冠中心搜索的最大距离 保证足够的搜索距离\n",
    "for i in range(T_num): \n",
    "    max_distances.append(c_size[i])\n",
    "\n",
    "lock_thresholds = [] # 范围内锁定像素的阈值，必须大于该值才能视为有效匹配,用来控制重叠区\n",
    "for i in range(T_num): \n",
    "    lock_thresholds.append(int(math.pi * (c_size[i]//2) **2) * glt) # 0意味可以无限重叠，1意味着禁止重叠\n",
    "\n",
    "# 单独填充最小patch 要求强匹配\n",
    "if T_num>3:\n",
    "    suit_map_binary_values[T_num-1] = 10\n",
    "    circle_masks[T_num-1][:] = 1\n",
    "    lock_thresholds[T_num-1] = c_size[T_num-1] **2 * mlt\n",
    "\n",
    "print(lock_thresholds)\n",
    "\n",
    "from datetime import datetime\n",
    "current_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "write_to_log(log_file_name, current_time)\n",
    "write_to_log(log_file_name, '\\nTmp:'+ str(c_size) +', suit_binaryT:' +str(suit_map_binary_values) +', shadowT:'+str(shandow_threshold)+', minimumT:'+str(minimum_threshold)+', skipT:' + str(skip_threshold)+', maxD:' + str(max_distances) +', lockT:' + str(lock_thresholds) +'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [06:17<00:00,  8.77s/it]\n"
     ]
    }
   ],
   "source": [
    "listpic = fnmatch.filter(os.listdir(sr_img_path), '*.tif')\n",
    "\n",
    "for img_name in tqdm(listpic):\n",
    "    img_full_path = sr_img_path + '/' + img_name\n",
    "    # sen_seg_full_path = semantic_segmentation_result_path + '/' + img_name[:-12] + 'result.tif' # 小图\n",
    "    sen_seg_full_path = semantic_segmentation_result_path + '/' + img_name\n",
    "\n",
    "    '''读取数据'''\n",
    "    data_ss, im_proj, im_geotrans = read_img(sen_seg_full_path)[:3]\n",
    "    data_img = read_img(img_full_path)[0]\n",
    "\n",
    "    '''将gdal格式转化为opencv格式'''\n",
    "    data_img = cv2.cvtColor(data_img.transpose(1, 2, 0), cv2.COLOR_RGB2BGR) # (c, h, w) -> (h, w, c) & RGB->BGR\n",
    "\n",
    "    '''少量特定预处理'''\n",
    "    height, width, channel = shape(data_img)\n",
    "    data_ss = cv2.resize(data_ss, (width, height)) # 处理裁剪中的些微偏移\n",
    "\n",
    "    '''掩膜操作'''\n",
    "    # 将掩膜中前景的像素设置为1，背景的像素设置为0\n",
    "    binary_mask = (data_ss == foreground_value).astype(np.uint8)\n",
    "    # 将原始图像和二值化的掩膜相乘，仅保留前景像素\n",
    "    masked_img = np.zeros((height, width, channel), dtype=np.uint8)\n",
    "\n",
    "    for i in range(channel):\n",
    "        masked_img[:,:,i] = data_img[:,:,i] * binary_mask\n",
    "\n",
    "    # 新建标记像素\n",
    "    marker_img = np.zeros((height, width), dtype=np.uint8)\n",
    "    marker_img = masked_img[:,:,2].copy() # 复制NIR2波段\n",
    "\n",
    "    T = 235\n",
    "    marker_img[marker_img < T] = 0\n",
    "    marker_img[marker_img > T] = 255\n",
    "\n",
    "    # 去除阴影\n",
    "    rt = masked_img[:,:,2].copy() # 以第红外波段为基准二值化\n",
    "    rt[rt<=shandow_threshold] = 0\n",
    "    rt[rt>shandow_threshold] = 255\n",
    "\n",
    "    # 构造连通图\n",
    "    opening = rt.copy() # 230920 取消应用形态学预处理\n",
    "    markers_com = opening.copy()\n",
    "\n",
    "\n",
    "    # Find connected components in the binary mask\n",
    "    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(markers_com, connectivity=4)\n",
    "\n",
    "\n",
    "    ## Create a random color map for visualization\n",
    "    # 设置随机种子以确保生成的随机数相同\n",
    "    np.random.seed(9145)\n",
    "    colorTab = np.zeros((num_labels, 3))\n",
    "\n",
    "    # 生成0~255之间的随机数\n",
    "    for i in range(len(colorTab)):\n",
    "        aa = np.random.uniform(0, 255)\n",
    "        bb = np.random.uniform(0, 255)\n",
    "        cc = np.random.uniform(0, 255)\n",
    "        colorTab[i] = np.array([aa, bb, cc], np.uint8)\n",
    "    colorTab[0] = [0, 0, 0]\n",
    "\n",
    "    # Apply the color map to the labels to visualize the connected components\n",
    "    # 遍历marks每一个元素值，对每一个区域进行颜色填充\n",
    "    label_vis = np.zeros((height, width, 3), dtype=np.uint8)\n",
    "\n",
    "    for i in range(height):\n",
    "        for j in range(width):\n",
    "            # index值一样的像素表示在一个区域\n",
    "            index = labels[i][j]\n",
    "            if index == 0:\n",
    "                continue\n",
    "            else:\n",
    "                label_vis[i][j] = colorTab[index]\n",
    "\n",
    "    '''胡杨填充'''\n",
    "    suit_map = np.zeros((T_num, height, width), dtype=np.float64) # 新建适宜度图\n",
    "    suitmap_for_vis = suit_map.copy()\n",
    "    minimum_threshold = minimum_threshold # 单株胡杨的最低识别阈值\n",
    "    populus_center = [] # 储存识别的胡杨中心\n",
    "    skip_threshold = skip_threshold # 如果有效像素比例低于该阈值则自动跳过\n",
    "\n",
    "    # print('calculating suitability map...')\n",
    "    for label in range(1, num_labels):  # 从1开始，跳过背景标签0\n",
    "        area = stats[label, cv2.CC_STAT_AREA]\n",
    "        x, y, p_width, p_height = stats[label, cv2.CC_STAT_LEFT], stats[label, cv2.CC_STAT_TOP], stats[label, cv2.CC_STAT_WIDTH], stats[label, cv2.CC_STAT_HEIGHT]\n",
    "        \n",
    "        # 处理极小connected component 判断单株胡杨\n",
    "        if p_width<c_size[0] and p_height<c_size[0]: # 当patch长宽均小于最大模板尺寸时被认为是极小patch\n",
    "            if p_width > minimum_threshold and p_height > minimum_threshold:\n",
    "                populus_center.append([y+p_height//2, x+p_width//2, -1])\n",
    "                continue\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "        # 正常connected component\n",
    "        # 生成适宜度图\n",
    "        for k in range(T_num): # k需要和模板数一致\n",
    "            for i in range(0, p_height):\n",
    "                for j in range(0, p_width):\n",
    "                    if y+i+c_size[k] < height and x+j+c_size[k] < width: # 防止越界\n",
    "                        tmp_labels = labels[y+i: y+i+c_size[k], x+j: x+j+c_size[k]].copy()\n",
    "                        tmp_labels[tmp_labels!=label] = 0\n",
    "                        tmp_labels[tmp_labels==label] = 1\n",
    "                        if cal_patch_march_num(tmp_labels, circle_masks[k]) >= skip_threshold * sum(circle_masks[k]): # 首先判断前景匹配的比例是否足够大\n",
    "                            tmp_img = data_img[y+i: y+i+c_size[k], x+j: x+j+c_size[k], :].copy() # opencv左上角出发，向右为x轴，向下为y轴\n",
    "                            average_distance = average_euclidean_distance(Tempalte[k], tmp_img, circle_masks[k]) # 计算模板和小块影像的欧式距离\n",
    "                            average_distance = 255-average_distance # 使更大的值对应更好的适宜度，此时average_distance取值应在0~255之间\n",
    "                            suit_map[k, y+i, x+j] = average_distance # 树冠左上角位置为(x,y)\n",
    "                            suitmap_for_vis[k, y+i+c_size[k]//2, x+j+c_size[k]//2] = average_distance\n",
    "                        else:\n",
    "                            continue # 前景比例不足直接跳过，用默认的0作为适宜度最终值，减少计算量\n",
    "                    else:\n",
    "                        continue\n",
    "\n",
    "    ## 处理适宜度图\n",
    "    # 计算非零像素的值\n",
    "    nonzero_values = []\n",
    "    for i in range(T_num):\n",
    "        tmp_suit_map = suit_map[i,:,:]\n",
    "        nonzero_value = tmp_suit_map[tmp_suit_map > 0]\n",
    "        nonzero_values.append(nonzero_value)\n",
    "\n",
    "    # 计算前x%分位数\n",
    "    threshold_values = []\n",
    "    for i in range(T_num):\n",
    "        if (len(nonzero_values[i]) > 1):\n",
    "            threshold_values.append(np.percentile(nonzero_values[i], suit_map_binary_values[i])) # 参数二为分位数值 它使得至少有 p% 的数据项小于或等于这个值，且至少有 (100-p)% 的数据项大于或等于这个值。\n",
    "        else:\n",
    "            threshold_values.append(1) # 处理无适宜位置的情况\n",
    "\n",
    "    lock_map = opening.copy() # 锁定图中，值0为锁定像素，值1为未锁定像素 初始状态与形态学处理后的语义分割结果一致\n",
    "    lock_map[lock_map==255] = 1    \n",
    "\n",
    "    ## 广度优先搜索\n",
    "    # 初始化\n",
    "    directions = [(-1, 0), (1, 0), (0, -1), (0, 1)]\n",
    "\n",
    "    # print('searching crown centers...')\n",
    "    for k in range(T_num): # k需要和模板数一致\n",
    "        for i in range(0, height-c_size[k]):\n",
    "            for j in range(0, width-c_size[k]):\n",
    "\n",
    "                visited = np.zeros((height, width), dtype=bool) # 在每次寻找起点时重置访问数组 这种方法会引起大量重复搜索，但适合应用情况\n",
    "                max_distance = max_distances[k] # 搜索的最大距离，当前设置为模板圆半径\n",
    "                max_value = -999\n",
    "\n",
    "                if suit_map[k, i, j] > threshold_values[k] and not visited[i, j] and lock_map[i,j]==1 and cal_lockmap_match_num(lock_map[i: i+c_size[k], j: j+c_size[k]], circle_masks[k]) >= lock_thresholds[k]:\n",
    "                    # 满足条件才能作为有效搜索起点 1.合适度值大于阈值 2.本身没有被锁定 3.范围内不得有过少有效像素（过多被锁定像素）\n",
    "                    queue = deque([(i, j, 0)])  # 添加第三个元素表示距离\n",
    "                    visited[i][j] = True\n",
    "                    max_value = suit_map[k, i, j]\n",
    "                    max_coords = (i, j)\n",
    "\n",
    "                    while queue:\n",
    "                        h, w, distance = queue.popleft()\n",
    "                        if distance > max_distance:\n",
    "                            continue\n",
    "\n",
    "                        for dh, dw in directions:\n",
    "                            nh, nw = h + dh, w + dw\n",
    "                            if 0 <= nh < height and 0 <= nw < width and suit_map[k, nh, nw] > threshold_values[k] and not visited[nh][nw] and lock_map[nh,nw]==1 and cal_lockmap_match_num(lock_map[nh: nh+c_size[k], nw: nw+c_size[k]], circle_masks[k]) >= lock_thresholds[k]:\n",
    "                                # 满足条件作为下一个有效的搜索值：12.未越界 3.合适度大于阈值 4.没有被访问过 5.本身没有被锁定 6.范围内不得有过少有效像素（过多被锁定像素）\n",
    "                                queue.append((nh, nw, distance + 1))\n",
    "                                visited[nh][nw] = True\n",
    "                                if suit_map[k, nh, nw] > max_value:\n",
    "                                    max_value = suit_map[k, nh, nw]\n",
    "                                    max_coords = (nh, nw)\n",
    "                    \n",
    "                    # queue为空，获得该次检索的最优位置max_coords\n",
    "                    for m in range(c_size[k]): # 更新锁定图\n",
    "                        for n in range(c_size[k]):\n",
    "                            if circle_masks[k][m][n] == 1:\n",
    "                                lock_map[max_coords[0]+m, max_coords[1]+n] = 0\n",
    "                                \n",
    "                    populus_center.append([max_coords[0]+c_size[k]//2, max_coords[1]+c_size[k]//2, k]) # 添加检索到的胡杨中心     \n",
    "\n",
    "    '''输出胡杨统计点到shp'''\n",
    "    '''新建输出shp'''\n",
    "    os.environ['GDAL_DATA'] = r'C:\\Users\\75198\\.conda\\envs\\learn\\Lib\\site-packages\\GDAL-2.4.1-py3.6-win-amd64.egg-info\\gata-data'  # 防止报error4错误\n",
    "\n",
    "    gdal.SetConfigOption(\"GDAL_FILENAME_IS_UTF8\", \"YES\")\n",
    "    gdal.SetConfigOption(\"SHAPE_ENCODING\", \"GBK\")\n",
    "\n",
    "    ogr.RegisterAll()  # 注册所有的驱动\n",
    "\n",
    "    driver = ogr.GetDriverByName('ESRI Shapefile')\n",
    "\n",
    "    prj = osr.SpatialReference()\n",
    "    prj.ImportFromWkt(im_proj)  # 读取栅格数据的投影信息，用来为后面生成的矢量做准备\n",
    "\n",
    "    '''准备输出'''\n",
    "    out_shp_full_path = output_shp_path + '/' +img_name[:-4] + '_populus_infer.shp'\n",
    "    if Path(out_shp_full_path).exists():\n",
    "        driver.DeleteDataSource(out_shp_full_path)\n",
    "    out_ds = driver.CreateDataSource(out_shp_full_path)\n",
    "    out_lyr = out_ds.CreateLayer(\n",
    "        out_shp_full_path, prj, ogr.wkbPoint)\n",
    "    def_out_feature = out_lyr.GetLayerDefn()  # 读取feature类型\n",
    "\n",
    "    oField = ogr.FieldDefn('type', ogr.OFTInteger)\n",
    "    out_lyr.CreateField(oField)\n",
    "\n",
    "    '''遍历输出'''\n",
    "    # print('outputing...')\n",
    "    for i in range(len(populus_center)):\n",
    "        point = ogr.Geometry(ogr.wkbPoint)\n",
    "        x_coord, y_coord = imagexy2geo(im_geotrans, populus_center[i][0], populus_center[i][1])\n",
    "        write_point_to_layer([x_coord, y_coord, populus_center[i][2]], out_lyr, def_out_feature)\n",
    "    out_ds.Destroy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
